# CTVO - Hybrid Virtual Try-On Pipeline

A modular, hybrid architecture for virtual try-on applications combining traditional computer vision with modern deep learning techniques.

## ğŸ—ï¸ Architecture Overview

CTVO implements a 4-stage pipeline for high-quality virtual try-on:

- **Stage 1**: Human Parsing & Pose Estimation
- **Stage 2**: Cloth Warping  
- **Stage 3**: Fusion Generation
- **Stage 4**: NeRF Multi-view Rendering

## ğŸ“ Project Structure

```
ctvo-project/
â”‚
â”œâ”€â”€ ctvo_core/                               # Main source package
â”‚   â”œâ”€â”€ stage1_parsing_pose/                 # Human parsing & pose estimation
â”‚   â”‚   â”œâ”€â”€ model_parsing.py
â”‚   â”‚   â”œâ”€â”€ model_pose.py
â”‚   â”‚   â”œâ”€â”€ run_pose.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ stage2_cloth_warping/                # Cloth warping
â”‚   â”‚   â”œâ”€â”€ UNet.py
â”‚   â”‚   â”œâ”€â”€ GMM.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”œâ”€â”€ run_warp.py
â”‚   â”‚   â””â”€â”€ pretrained_weights/
â”‚   â”‚       â””â”€â”€ unet_wrap.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ stage3_fusion/                       # Fusion generation
â”‚   â”‚   â”œâ”€â”€ TryOnGenerator.py
â”‚   â”‚   â”œâ”€â”€ FusionNet.py
â”‚   â”‚   â”œâ”€â”€ losses.py
â”‚   â”‚   â”œâ”€â”€ train_fusion.py
â”‚   â”‚   â”œâ”€â”€ eval_fusion.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ stage4_nerf/                        # NeRF multi-view
â”‚   â”‚   â”œâ”€â”€ model_nerf.py
â”‚   â”‚   â”œâ”€â”€ renderer.py
â”‚   â”‚   â”œâ”€â”€ dataset_nerf.py
â”‚   â”‚   â”œâ”€â”€ train_nerf.py
â”‚   â”‚   â”œâ”€â”€ eval_multiview.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ losses/                              # Shared loss functions
â”‚   â”‚   â”œâ”€â”€ perceptual_loss.py
â”‚   â”‚   â”œâ”€â”€ style_loss.py
â”‚   â”‚   â”œâ”€â”€ mask_losses.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                               # Shared utilities
â”‚   â”‚   â”œâ”€â”€ image_io.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ visualizer.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/                                    # Data directory
â”‚   â”œâ”€â”€ custom_dataset/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â”‚   â”œâ”€â”€ cloth/
â”‚   â”‚   â”‚   â”œâ”€â”€ image-parse/
â”‚   â”‚   â”‚   â”œâ”€â”€ agnostic-parse/
â”‚   â”‚   â”‚   â”œâ”€â”€ openpose/
â”‚   â”‚   â”‚   â”œâ”€â”€ warped_cloth/
â”‚   â”‚   â”‚   â”œâ”€â”€ pairs.txt
â”‚   â”‚   â”‚   â””â”€â”€ meta.json
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚       â”œâ”€â”€ image/
â”‚   â”‚       â”œâ”€â”€ cloth/
â”‚   â”‚       â”œâ”€â”€ image-parse/
â”‚   â”‚       â”œâ”€â”€ openpose/
â”‚   â”‚       â””â”€â”€ warped_cloth/
â”‚   â”‚
â”‚   â”œâ”€â”€ synthetic_augmented/
â”‚   â”‚   â”œâ”€â”€ zero123/
â”‚   â”‚   â”œâ”€â”€ triposr/
â”‚   â”‚   â”œâ”€â”€ depth/
â”‚   â”‚   â””â”€â”€ readme.txt
â”‚   â”‚
â”‚   â””â”€â”€ marquis_viton_hd/
â”‚       â”œâ”€â”€ train/
â”‚       â”œâ”€â”€ test/
â”‚       â””â”€â”€ metadata.txt
â”‚
â”œâ”€â”€ results/                                 # Results directory
â”‚   â”œâ”€â”€ stage2_samples/
â”‚   â”œâ”€â”€ stage3_previews/
â”‚   â””â”€â”€ stage4_multiview/
â”‚
â”œâ”€â”€ configs/                                 # Configuration files
â”‚   â”œâ”€â”€ base.yaml
â”‚   â”œâ”€â”€ stage3_fusion.yaml
â”‚   â”œâ”€â”€ stage4_nerf.yaml
â”‚   â””â”€â”€ lightning_trainer.yaml
â”‚
â”œâ”€â”€ scripts/                                 # Run scripts
â”‚   â”œâ”€â”€ run_stage1.py
â”‚   â”œâ”€â”€ run_stage2.py
â”‚   â”œâ”€â”€ run_stage3.py
â”‚   â”œâ”€â”€ run_stage4.py
â”‚   â””â”€â”€ train_all.sh
â”‚
â”œâ”€â”€ tests/                                   # Test files
â”‚   â”œâ”€â”€ test_imports.py
â”‚   â”œâ”€â”€ test_losses.py
â”‚   â””â”€â”€ test_dataset_integrity.py
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd ctvo-project
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Download pre-trained models:
```bash
# Download Stage 1 models
wget <parsing-model-url> -O ctvo_core/stage1_parsing_pose/pretrained_models/parsing_lip.onnx
wget <pose-model-url> -O ctvo_core/stage1_parsing_pose/pretrained_models/body_pose_model.pth

# Download Stage 2 models
wget <warp-model-url> -O ctvo_core/stage2_cloth_warping/pretrained_weights/unet_wrap.pth
```

### Running Individual Stages

#### Stage 1: Human Parsing & Pose Estimation
```bash
python scripts/run_stage1.py \
    --input_image data/person.jpg \
    --output_dir results/stage1 \
    --visualize
```

#### Stage 2: Cloth Warping
```bash
python scripts/run_stage2.py \
    --person_img data/person.jpg \
    --cloth_img data/cloth.jpg \
    --parsing_map results/stage1/parsing_maps/output.png \
    --pose_json results/stage1/keypoints_json/pose.json \
    --output_path results/stage2/warped_cloth.jpg \
    --visualize
```

#### Stage 3: Fusion Generation
```bash
# Training
python scripts/run_stage3.py \
    --mode train \
    --data_dir data/custom_dataset \
    --config configs/stage3_fusion.yaml

# Evaluation
python scripts/run_stage3.py \
    --mode eval \
    --checkpoint checkpoints/stage3_fusion/best_model.pth \
    --data_dir data/custom_dataset \
    --output_dir results/stage3_previews
```

#### Stage 4: NeRF Multi-view Generation
```bash
# Training
python scripts/run_stage4.py \
    --mode train \
    --data_dir data/synthetic_augmented \
    --config configs/stage4_nerf.yaml

# Evaluation
python scripts/run_stage4.py \
    --mode eval \
    --checkpoint checkpoints/stage4_nerf/best_model.pth \
    --output_dir results/stage4_multiview \
    --num_views 8
```

### Training All Stages
```bash
bash scripts/train_all.sh
```

## ğŸ§ª Testing

Run the test suite to validate the installation:

```bash
# Test imports
python tests/test_imports.py

# Test loss functions
python tests/test_losses.py

# Test dataset integrity
python tests/test_dataset_integrity.py
```

## ğŸ“Š Configuration

The pipeline uses YAML configuration files for easy customization:

- `configs/base.yaml`: Base configuration shared across stages
- `configs/stage3_fusion.yaml`: Stage 3 specific settings
- `configs/stage4_nerf.yaml`: Stage 4 specific settings
- `configs/lightning_trainer.yaml`: PyTorch Lightning trainer settings

## ğŸ”§ Key Features

### Stage 1: Human Parsing & Pose Estimation
- ONNX-based human parsing using LIP/ATR models
- MobileNet-based pose estimation
- Integrated processing pipeline

### Stage 2: Cloth Warping
- UNet-based cloth warping
- GMM (Geometric Matching Module) support
- Pose-aware warping

### Stage 3: Fusion Generation
- Multiple fusion architectures (TryOnGenerator, FusionNet)
- Advanced loss functions (perceptual, style, mask-aware)
- PyTorch Lightning integration

### Stage 4: NeRF Multi-view Generation
- Neural Radiance Fields for multi-view rendering
- Volume rendering pipeline
- Camera path generation

### Shared Components
- Comprehensive loss functions
- Data loading utilities
- Visualization tools
- Logging system

## ğŸ“ˆ Performance

The pipeline is designed for:
- **Efficiency**: Modular design allows for stage-wise optimization
- **Scalability**: PyTorch Lightning for distributed training
- **Quality**: Advanced loss functions and multi-view consistency
- **Flexibility**: Configurable architecture and training parameters

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenPose for pose estimation models
- VITON for cloth warping techniques
- NeRF for neural rendering
- PyTorch Lightning for training infrastructure

## ğŸ“ Support

For questions and support, please open an issue on GitHub or contact the development team.